<html>
  <head>

    <!--
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands"></script>
    -->
   
   <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.22.0"></script>  
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.5.4"></script>
  </head>
  <body>

<button id="left" onmousedown="collect(0, this)" onChange="alert()">Record multiple times the word: </button>
<input id="myLeftIn" type=text value="Left"> <br>
<button id="right" onmousedown="collect(1, this)" onChange="document.getElementById(mySpanRight).value = this.value">Record multiple times the word: </button>
<input id="myRightIn" type=text value="Right"> <br>
<button id="noise" onmousedown="collect(2, this)" >Record the background Noise </button>
<input id="myNoiseIn" type=text value="Noise"> <br>


<br/><br/>
<button id="train" onclick="train()">Train</button>
Epochs: <input id="myENum" type=number size=5 value=10 >
<div id="console"></div>

<br/><br/>
<button id="listen" onclick="listen()">Listen</button>
<span id="mySpanLeft"> Left:</span> <input type="range" id="output" min="0" max="10" step="0.1"> <span id="mySpanRight"> :Right</span><br>

<script>

let recognizer;

function predictWord() {
 // Array of words that the recognizer is trained to recognize.
 const words = recognizer.wordLabels();
 recognizer.listen(({scores}) => {
   // Turn scores into a list of (score,word) pairs.
   scores = Array.from(scores).map((s, i) => ({score: s, word: words[i]}));
   // Find the most probable word.
   scores.sort((s1, s2) => s2.score - s1.score);
   document.querySelector('#console').textContent = scores[0].word;
 }, {probabilityThreshold: 0.75});
}


// One frame is ~23ms of audio.
const NUM_FRAMES = 3;
let examples = [];

function collect(label, myButton) {
 myButton.style.backgroundColor = 'green';
 if (recognizer.isListening()) { 
   myButton.style.backgroundColor='lightGray';
   return recognizer.stopListening();
 }

 recognizer.listen(async ({spectrogram: {frameSize, data}}) => {
   let vals = normalize(data.subarray(-frameSize * NUM_FRAMES));
   examples.push({vals, label});
   document.querySelector('#console').textContent =`${examples.length} examples collected`;
 }, {
   overlapFactor: 0.999,
   includeSpectrogram: true,
   invokeCallbackOnNoiseAndUnknown: true
 });
}

function normalize(x) {
 const mean = -100;
 const std = 10;
 return x.map(x => (x - mean) / std);
}

async function app() {
 recognizer = speechCommands.create('BROWSER_FFT');
 await recognizer.ensureModelLoaded();
 // Add this line.
 buildModel();
}

app();


const INPUT_SHAPE = [NUM_FRAMES, 232, 1];
let model;

async function train() {
  const myEpochs = parseInt(document.getElementById('myENum').value)
 toggleButtons(false);
 const ys = tf.oneHot(examples.map(e => e.label), 3);
 const xsShape = [examples.length, ...INPUT_SHAPE];
 const xs = tf.tensor(flatten(examples.map(e => e.vals)), xsShape);

 await model.fit(xs, ys, {
   batchSize: 16,
   epochs: myEpochs,
   callbacks: {
     onEpochEnd: (epoch, logs) => {
       document.querySelector('#console').textContent =
           `Accuracy: ${(logs.acc * 100).toFixed(1)}% Epoch: ${epoch + 1}`;
     }
   }
 });
 tf.dispose([xs, ys]);
 toggleButtons(true);
}

function buildModel() {
 model = tf.sequential();
 model.add(tf.layers.depthwiseConv2d({
   depthMultiplier: 8,
   kernelSize: [NUM_FRAMES, 3],
   activation: 'relu',
   inputShape: INPUT_SHAPE
 }));
 model.add(tf.layers.maxPooling2d({poolSize: [1, 2], strides: [2, 2]}));
 model.add(tf.layers.flatten());
 model.add(tf.layers.dense({units: 3, activation: 'softmax'}));
 const optimizer = tf.train.adam(0.01);
 model.compile({
   optimizer,
   loss: 'categoricalCrossentropy',
   metrics: ['accuracy']
 });
}

function toggleButtons(enable) {
 document.querySelectorAll('button').forEach(b => b.disabled = !enable);
}

function flatten(tensors) {
 const size = tensors[0].length;
 const result = new Float32Array(tensors.length * size);
 tensors.forEach((arr, i) => result.set(arr, i * size));
 return result;
}


async function moveSlider(labelTensor) {
 const label = (await labelTensor.data())[0];
  if (label == 0) {
    document.getElementById('console').textContent = document.getElementById('myLeftIn').value;
  }
  if (label == 1) {
    document.getElementById('console').textContent = document.getElementById('myRightIn').value;
  }
  if (label == 2) {
    document.getElementById('console').textContent = document.getElementById('myNoiseIn').value;
    return;
  }
    /*
 document.getElementById('console').textContent = label;
 if (label == 2) {
   return;
 }
  */
 let delta = 0.1;
 const prevValue = +document.getElementById('output').value;
 document.getElementById('output').value =
     prevValue + (label === 0 ? -delta : delta);
}

function listen() {
 if (recognizer.isListening()) {
   recognizer.stopListening();
   toggleButtons(true);
   document.getElementById('listen').textContent = 'Listen';
   return;
 }
 toggleButtons(false);
 document.getElementById('listen').textContent = 'Stop';
 document.getElementById('listen').disabled = false;

 recognizer.listen(async ({spectrogram: {frameSize, data}}) => {
   const vals = normalize(data.subarray(-frameSize * NUM_FRAMES));
   const input = tf.tensor(vals, [1, ...INPUT_SHAPE]);
   const probs = model.predict(input);
   const predLabel = probs.argMax(1);
   await moveSlider(predLabel);
   tf.dispose([input, probs, predLabel]);
 }, {
   overlapFactor: 0.999,
   includeSpectrogram: true,
   invokeCallbackOnNoiseAndUnknown: true
 });
}


</script>


  </body>
</html>
